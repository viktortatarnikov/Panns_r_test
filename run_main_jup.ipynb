{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c40f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../utils'))\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    " \n",
    "from config import (sample_rate, classes_num, mel_bins, fmin, fmax, window_size, \n",
    "    hop_size, window, pad_mode, center, ref, amin, top_db)\n",
    "from losses import get_loss_func\n",
    "from pytorch_utils import move_data_to_device, do_mixup\n",
    "from utilities import (create_folder, get_filename, create_logging, StatisticsContainer, Mixup)\n",
    "from data_generator import GtzanDataset, TrainSampler, EvaluateSampler, collate_fn\n",
    "from models import Transfer_Cnn14\n",
    "from evaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07917f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR=\"D:\\\\Py_things\\\\PyProjects\\\\Kvant_projects\\\\PANNS_R_TEST\\\\training\\\\datasets\\\\R_SOUNDS\"\n",
    "WORKSPACE=\"D:\\\\Py_things\\\\PyProjects\\\\Kvant_projects\\\\PANNS_R_TEST\\\\training\\\\workspaces\\\\music\"\n",
    "PRETRAINED_CHECKPOINT_PATH=\"D:\\\\Py_things\\\\PyProjects\\\\Kvant_projects\\\\PANNS_R_TEST\\\\panns_data\\\\Cnn14_mAP=0.431.pth\"\n",
    "FILENAME ='D:\\\\Py_things\\\\PyProjects\\\\Kvant_projects\\\\PANNS_R_TEST\\\\TrainPANNS\\\\fine-tuning-music-example\\\\jup_test\\\\run_main_jup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "900c1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    # Arugments & parameters\n",
    "#     dataset_dir = args.dataset_dir\n",
    "#     workspace = args.workspace\n",
    "#     holdout_fold = args.holdout_fold\n",
    "#     model_type = args.model_type\n",
    "#     pretrained_checkpoint_path = args.pretrained_checkpoint_path\n",
    "#     freeze_base = args.freeze_base\n",
    "#     loss_type = args.loss_type\n",
    "#     augmentation = args.augmentation\n",
    "#     learning_rate = args.learning_rate\n",
    "#     batch_size = args.batch_size\n",
    "#     resume_iteration = args.resume_iteration\n",
    "#     stop_iteration = args.stop_iteration\n",
    "#     device = 'cuda' if (args.cuda and torch.cuda.is_available()) else 'cpu'\n",
    "#     filename = args.filename\n",
    "#     num_workers = 8\n",
    "\n",
    "# впишем ручками параметры для тренировки\n",
    "    dataset_dir = DATASET_DIR\n",
    "    workspace = WORKSPACE\n",
    "    holdout_fold = 1\n",
    "    model_type = \"Transfer_Cnn14\"\n",
    "    pretrained_checkpoint_path = PRETRAINED_CHECKPOINT_PATH\n",
    "    freeze_base = False # это что?, пока так\n",
    "    loss_type = \"clip_nll\" #добавил ковычек\n",
    "    augmentation = 'mixup'\n",
    "    learning_rate = 1e-4\n",
    "    batch_size = 8\n",
    "    resume_iteration = 0\n",
    "    stop_iteration = 10 #пока чуть-чуть, но нужно сильно больше\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    filename = FILENAME #Пока так\n",
    "    num_workers = 8\n",
    "\n",
    "    loss_func = get_loss_func(loss_type)\n",
    "    pretrain = True if pretrained_checkpoint_path else False\n",
    "    \n",
    "    hdf5_path = os.path.join(workspace, 'features', 'waveform.h5')\n",
    "\n",
    "    checkpoints_dir = os.path.join(workspace, 'checkpoints', filename, \n",
    "        'holdout_fold={}'.format(holdout_fold), model_type, 'pretrain={}'.format(pretrain), \n",
    "        'loss_type={}'.format(loss_type), 'augmentation={}'.format(augmentation),\n",
    "         'batch_size={}'.format(batch_size), 'freeze_base={}'.format(freeze_base))\n",
    "    create_folder(checkpoints_dir)\n",
    "\n",
    "    statistics_path = os.path.join(workspace, 'statistics', filename, \n",
    "        'holdout_fold={}'.format(holdout_fold), model_type, 'pretrain={}'.format(pretrain), \n",
    "        'loss_type={}'.format(loss_type), 'augmentation={}'.format(augmentation), \n",
    "        'batch_size={}'.format(batch_size), 'freeze_base={}'.format(freeze_base), \n",
    "        'statistics.pickle')\n",
    "    create_folder(os.path.dirname(statistics_path))\n",
    "    \n",
    "    logs_dir = os.path.join(workspace, 'logs', filename, \n",
    "        'holdout_fold={}'.format(holdout_fold), model_type, 'pretrain={}'.format(pretrain), \n",
    "        'loss_type={}'.format(loss_type), 'augmentation={}'.format(augmentation), \n",
    "        'batch_size={}'.format(batch_size), 'freeze_base={}'.format(freeze_base))\n",
    "    create_logging(logs_dir, 'w')\n",
    "#     logging.info(args) # Пока закомитить\n",
    "\n",
    "    if 'cuda' in device:\n",
    "        logging.info('Using GPU.')\n",
    "    else:\n",
    "        logging.info('Using CPU. Set --cuda flag to use GPU.')\n",
    "\n",
    "    print('window size {}'.format(window_size))\n",
    "\n",
    "    # Model\n",
    "    Model = eval(model_type)\n",
    "    model = Model(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, \n",
    "        classes_num, freeze_base)\n",
    "\n",
    "    # Statistics\n",
    "    statistics_container = StatisticsContainer(statistics_path)\n",
    "\n",
    "    if pretrain:\n",
    "        logging.info('Load pretrained model from {}'.format(pretrained_checkpoint_path))\n",
    "        model.load_from_pretrain(pretrained_checkpoint_path)\n",
    "\n",
    "    if resume_iteration:\n",
    "        resume_checkpoint_path = os.path.join(checkpoints_dir, '{}_iterations.pth'.format(resume_iteration))\n",
    "        logging.info('Load resume model from {}'.format(resume_checkpoint_path))\n",
    "        resume_checkpoint = torch.load(resume_checkpoint_path)\n",
    "        model.load_state_dict(resume_checkpoint['model'])\n",
    "        statistics_container.load_state_dict(resume_iteration)\n",
    "        iteration = resume_checkpoint['iteration']\n",
    "    else:\n",
    "        iteration = 0\n",
    "\n",
    "    # Parallel\n",
    "    print('GPU number: {}'.format(torch.cuda.device_count()))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "    dataset = GtzanDataset()\n",
    "\n",
    "    # Data generator\n",
    "    train_sampler = TrainSampler(\n",
    "        hdf5_path=hdf5_path, \n",
    "        holdout_fold=holdout_fold, \n",
    "        batch_size=batch_size * 2 if 'mixup' in augmentation else batch_size)\n",
    "\n",
    "    validate_sampler = EvaluateSampler(\n",
    "        hdf5_path=hdf5_path, \n",
    "        holdout_fold=holdout_fold, \n",
    "        batch_size=batch_size)\n",
    "\n",
    "    # Data loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "        batch_sampler=train_sampler, collate_fn=collate_fn, \n",
    "        num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    validate_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "        batch_sampler=validate_sampler, collate_fn=collate_fn, \n",
    "        num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    if 'cuda' in device:\n",
    "        model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999),\n",
    "        eps=1e-08, weight_decay=0., amsgrad=True)\n",
    "\n",
    "    \n",
    "    if 'mixup' in augmentation:\n",
    "        mixup_augmenter = Mixup(mixup_alpha=1.)\n",
    "     \n",
    "    # Evaluator\n",
    "    evaluator = Evaluator(model=model)\n",
    "    \n",
    "    train_bgn_time = time.time()\n",
    "    \n",
    "    # Train on mini batches\n",
    "    for batch_data_dict in train_loader:\n",
    "\n",
    "        # import crash\n",
    "        # asdf\n",
    "        \n",
    "        # Evaluate\n",
    "        if iteration % 200 == 0 and iteration > 0:\n",
    "            if resume_iteration > 0 and iteration == resume_iteration:\n",
    "                pass\n",
    "            else:\n",
    "                logging.info('------------------------------------')\n",
    "                logging.info('Iteration: {}'.format(iteration))\n",
    "\n",
    "                train_fin_time = time.time()\n",
    "\n",
    "                statistics = evaluator.evaluate(validate_loader)\n",
    "                logging.info('Validate accuracy: {:.3f}'.format(statistics['accuracy']))\n",
    "\n",
    "                statistics_container.append(iteration, statistics, 'validate')\n",
    "                statistics_container.dump()\n",
    "\n",
    "                train_time = train_fin_time - train_bgn_time\n",
    "                validate_time = time.time() - train_fin_time\n",
    "\n",
    "                logging.info(\n",
    "                    'Train time: {:.3f} s, validate time: {:.3f} s'\n",
    "                    ''.format(train_time, validate_time))\n",
    "\n",
    "                train_bgn_time = time.time()\n",
    "\n",
    "        # Save model \n",
    "        if iteration % 2000 == 0 and iteration > 0:\n",
    "            checkpoint = {\n",
    "                'iteration': iteration, \n",
    "                'model': model.module.state_dict()}\n",
    "\n",
    "            checkpoint_path = os.path.join(\n",
    "                checkpoints_dir, '{}_iterations.pth'.format(iteration))\n",
    "                \n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logging.info('Model saved to {}'.format(checkpoint_path))\n",
    "        \n",
    "        if 'mixup' in augmentation:\n",
    "            batch_data_dict['mixup_lambda'] = mixup_augmenter.get_lambda(len(batch_data_dict['waveform']))\n",
    "        \n",
    "        # Move data to GPU\n",
    "        for key in batch_data_dict.keys():\n",
    "            batch_data_dict[key] = move_data_to_device(batch_data_dict[key], device)\n",
    "        \n",
    "        # Train\n",
    "        model.train()\n",
    "\n",
    "        if 'mixup' in augmentation:\n",
    "            batch_output_dict = model(batch_data_dict['waveform'], \n",
    "                batch_data_dict['mixup_lambda'])\n",
    "            \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "\n",
    "            batch_target_dict = {'target': do_mixup(batch_data_dict['target'], \n",
    "                batch_data_dict['mixup_lambda'])}\n",
    "            \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "        else:\n",
    "            batch_output_dict = model(batch_data_dict['waveform'], None)\n",
    "            \"\"\"{'clipwise_output': (batch_size, classes_num), ...}\"\"\"\n",
    "\n",
    "            batch_target_dict = {'target': batch_data_dict['target']}\n",
    "            \"\"\"{'target': (batch_size, classes_num)}\"\"\"\n",
    "\n",
    "        # loss\n",
    "        loss = loss_func(batch_output_dict, batch_target_dict)\n",
    "        print(iteration, loss)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Stop learning\n",
    "        if iteration == stop_iteration:\n",
    "            break \n",
    "\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87c4bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --dataset_dir=$DATASET_DIR \n",
    "# --workspace=$WORKSPACE \n",
    "# --holdout_fold=1 \n",
    "# --model_type=\"Transfer_Cnn14\" \n",
    "# --pretrained_checkpoint_path=$PRETRAINED_CHECKPOINT_PATH \n",
    "# --loss_type=clip_nll \n",
    "# --augmentation='mixup' \n",
    "# --learning_rate=1e-4 \n",
    "# --batch_size=8 \n",
    "# --resume_iteration=0 \n",
    "# --stop_iteration=10 \n",
    "# --cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd313fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Using CPU. Set --cuda flag to use GPU.\n",
      "root        : INFO     Using CPU. Set --cuda flag to use GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window size 1024\n",
      "window size 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Load pretrained model from D:\\Py_things\\PyProjects\\Kvant_projects\\PANNS_R_TEST\\panns_data\\Cnn14_mAP=0.431.pth\n",
      "root        : INFO     Load pretrained model from D:\\Py_things\\PyProjects\\Kvant_projects\\PANNS_R_TEST\\panns_data\\Cnn14_mAP=0.431.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transformers.file_utils: INFO     PyTorch version 2.1.0 available.\n",
      "transformers.file_utils: INFO     PyTorch version 2.1.0 available.\n",
      "transformers.modeling_xlnet: INFO     Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "transformers.modeling_xlnet: INFO     Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2017, grad_fn=<NegBackward0>)\n",
      "1 tensor(0.0795, grad_fn=<NegBackward0>)\n",
      "2 tensor(0.1132, grad_fn=<NegBackward0>)\n",
      "3 tensor(0.1167, grad_fn=<NegBackward0>)\n",
      "4 tensor(0.1649, grad_fn=<NegBackward0>)\n",
      "5 tensor(0.1435, grad_fn=<NegBackward0>)\n",
      "6 tensor(0.0927, grad_fn=<NegBackward0>)\n",
      "7 tensor(0.4546, grad_fn=<NegBackward0>)\n",
      "8 tensor(0.1858, grad_fn=<NegBackward0>)\n",
      "9 tensor(0.0934, grad_fn=<NegBackward0>)\n",
      "10 tensor(0.1245, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e7655d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Py_things\\\\PyProjects\\\\Kvant_projects\\\\PANNS_R_TEST\\\\TrainPANNS\\x0cine-tuning-music-example\\\\jup_test\\run_main_jup'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159cda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
